{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eeWCiqOWf7xx",
    "outputId": "f539af20-b63a-46ab-cdb6-3d3fa3f8059d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "movies=pd.read_csv(\"movies.csv\")\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "oDy4jTDXf--B"
   },
   "outputs": [],
   "source": [
    "def load_data(movies_df, ratings_df):\n",
    "    # Load the data from CSV files\n",
    "    movies = movies_df.copy()\n",
    "    ratings = ratings_df.copy()\n",
    "\n",
    "    # Print the columns to debug\n",
    "    print(\"Movies DataFrame columns:\", movies.columns)\n",
    "\n",
    "    # Check if 'title' exists in movies DataFrame\n",
    "    if 'title' not in movies.columns:\n",
    "        raise KeyError(\"The 'title' column is missing in the movies DataFrame.\")\n",
    "\n",
    "    # Create a list of genres for binary encoding\n",
    "    genres = [\n",
    "        'Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
    "        'Crime', 'Documentary', 'Drama', 'Fantasy', 'Horror',\n",
    "        'Mystery', 'Romance', 'Sci-Fi', 'Thriller'\n",
    "    ]\n",
    "\n",
    "    # Prepare the movies DataFrame\n",
    "    # Extract year from title and compute average ratings\n",
    "    movies['year'] = movies['title'].str.extract(r'\\((\\d{4})\\)')\n",
    "    movies['title'] = movies['title'].str.replace(r'\\s*\\(\\d{4}\\)', '', regex=True).str.strip()\n",
    "\n",
    "    # Calculate average ratings for each movie\n",
    "    avg_ratings = ratings.groupby('movieId')['rating'].mean().reset_index()\n",
    "    avg_ratings.columns = ['movieId', 'avg_rating']\n",
    "\n",
    "    # Merge the average ratings with movies DataFrame\n",
    "    movies = movies.merge(avg_ratings, on='movieId', how='left')\n",
    "\n",
    "    # One-hot encode genres into binary columns\n",
    "    for genre in genres:\n",
    "        movies[genre] = movies['genres'].str.contains(genre).astype(int)\n",
    "\n",
    "    # Drop the original genres column\n",
    "    movies = movies.drop(columns=['genres', 'title'], axis=1)\n",
    "\n",
    "    # Prepare the user DataFrame\n",
    "    user_data = ratings.groupby('userId').agg(\n",
    "        rating_count=('rating', 'count'),\n",
    "        avg_rating=('rating', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Calculate average ratings for each genre per user\n",
    "    for genre in genres:\n",
    "        user_data[genre + '_avg'] = \\\n",
    "        ratings[ratings['movieId'].isin(movies[movies[genre] == 1]['movieId'])].groupby('userId')[\n",
    "            'rating'].mean().fillna(0)\n",
    "\n",
    "    # Merge user data with the binary genre data\n",
    "    user_data = user_data.fillna(0)\n",
    "    # Return user data, movies, and the original movies DataFrame\n",
    "    return user_data, movies, movies\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "LVTpiYyIhuVq"
   },
   "outputs": [],
   "source": [
    "def get_user_data():\n",
    "    ratings_df = pd.read_csv('ratings.csv')  # Adjust the filename as needed\n",
    "    lastid = ratings_df['userId'].iloc[-1]\n",
    "    user_data = []\n",
    "\n",
    "    # Collecting user input for the ratings\n",
    "    user_data.append(int(lastid + 1))\n",
    "    user_data.append(float(input(\"Enter the Average rating: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Action: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Adventure: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Animation: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Children: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Comedy: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Crime: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Documentary: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Drama: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Fantasy: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Horror: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Mystery: \")))\n",
    "    user_data.append(float(input(\"Enter the rating of Romance: \")))\n",
    "\n",
    "    return user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Tp10TJr1hJ_O"
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, y_test):\n",
    "    # Neural networks for user and movie vectors\n",
    "    user_NN = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(32),\n",
    "    ])\n",
    "\n",
    "    movie_NN = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(32),\n",
    "    ])\n",
    "\n",
    "    # Inputs for users and movies\n",
    "    user_input = tf.keras.Input(shape=(X_train.shape[1],))  # Shape (features,)\n",
    "    movie_input = tf.keras.Input(shape=(y_train.shape[1],))  # Shape (features,)\n",
    "\n",
    "    # Get user and movie vectors\n",
    "    user_vector = user_NN(user_input)\n",
    "    movie_vector = movie_NN(movie_input)\n",
    "\n",
    "    # Compute dot product\n",
    "    output = tf.keras.layers.Dot(axes=1)([user_vector, movie_vector])\n",
    "\n",
    "    # Build and compile the model (Don't redefine it later)\n",
    "    model = tf.keras.Model(inputs=[user_input, movie_input], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "    # Train the model\n",
    "    model.fit([X_train, y_train], y_train, epochs=10, batch_size=32)\n",
    "\n",
    "    # Evaluate the model (Fix the input format)\n",
    "    loss = model.evaluate([X_test, y_test], y_test)\n",
    "    print(f\"Test Loss: {loss}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movie(model, user_data, movies_scaled, movies_original):\n",
    "    user_vector = np.expand_dims(user_data, axis=0)  # Shape (1, 17)\n",
    "    \n",
    "    # Repeat user_vector to match movies_scaled shape\n",
    "    user_vector_repeated = np.repeat(user_vector, movies_scaled.shape[0], axis=0)  # Shape (86537, 17)\n",
    "    print(\"User vector shape:\", user_vector_repeated.shape)  # Should be (86537, 17)\n",
    "    print(\"Movies scaled shape:\", movies_scaled.shape)  # Should be (86537, 17)\n",
    "    if user_vector_repeated.shape[1] != 17:\n",
    "        missing_columns = 17 - user_vector_repeated.shape[1]\n",
    "        user_vector_repeated = np.pad(user_vector_repeated, ((0, 0), (0, missing_columns)), mode='constant')\n",
    "    if movies_scaled.shape[1] != 17:\n",
    "        missing_columns = 17 - movies_scaled.shape[1]\n",
    "        movies_scaled = np.pad(movies_scaled, ((0, 0), (0, missing_columns)), mode='constant')\n",
    "\n",
    "    # Predict ratings\n",
    "    predicted_ratings = model.predict([user_vector_repeated, movies_scaled])\n",
    "\n",
    "    # Get the index of the highest predicted rating\n",
    "    top_movie_index = np.argmax(predicted_ratings)\n",
    "\n",
    "    # Get the recommended movie\n",
    "    recommended_movie = movies_original.iloc[top_movie_index]\n",
    "    \n",
    "\n",
    "    return recommended_movie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(movies_scaled,user_scaled):\n",
    "    # Ensure movies_scaled and user_scaled have the same length\n",
    "    min_samples = min(len(movies_scaled), len(user_scaled))\n",
    "\n",
    "    movies_scaled = movies_scaled[:min_samples]\n",
    "    user_scaled = user_scaled[:min_samples]\n",
    "    X_train, X_test = train_test_split(user_scaled, test_size=0.4, random_state=42)\n",
    "#Movies data is used for both training and testing\n",
    "    y_train, y_test = movies_scaled[:len(X_train)], movies_scaled[len(X_train):]\n",
    "# Re-split correctly\n",
    "    print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "    print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n",
    "    X_train = X_train.iloc[:-17307]\n",
    "    y_train=y_train.iloc[:-17307]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies DataFrame columns: Index(['movieId', 'title', 'genres'], dtype='object')\n",
      "X_train: (51922, 17) y_train: (51922, 17)\n",
      "X_test: (34615, 17) y_test: (34615, 17)\n",
      "Epoch 1/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: nan\n",
      "Epoch 2/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: nan\n",
      "Epoch 3/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan\n",
      "Epoch 4/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan\n",
      "Epoch 5/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan\n",
      "Epoch 6/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: nan\n",
      "Epoch 7/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: nan\n",
      "Epoch 8/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan\n",
      "Epoch 9/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan\n",
      "Epoch 10/10\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: nan\n",
      "\u001b[1m1082/1082\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: nan\n",
      "Test Loss: nan\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the Average rating:  4\n",
      "Enter the rating of Action:  4\n",
      "Enter the rating of Adventure:  4\n",
      "Enter the rating of Animation:  2\n",
      "Enter the rating of Children:  2\n",
      "Enter the rating of Comedy:  2\n",
      "Enter the rating of Crime:  2\n",
      "Enter the rating of Documentary:  2\n",
      "Enter the rating of Drama:  4\n",
      "Enter the rating of Fantasy:  3\n",
      "Enter the rating of Horror:  4\n",
      "Enter the rating of Mystery:  4\n",
      "Enter the rating of Romance:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User vector shape: (86537, 14)\n",
      "Movies scaled shape: (86537, 17)\n",
      "\u001b[1m2705/2705\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "movieId               1\n",
       "year               1995\n",
       "avg_rating     3.893508\n",
       "Action                0\n",
       "Adventure             1\n",
       "Animation             1\n",
       "Children              1\n",
       "Comedy                1\n",
       "Crime                 0\n",
       "Documentary           0\n",
       "Drama                 0\n",
       "Fantasy               1\n",
       "Horror                0\n",
       "Mystery               0\n",
       "Romance               0\n",
       "Sci-Fi                0\n",
       "Thriller              0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#running\n",
    "user_data, movies_scaled, movies_original=load_data(movies,ratings)\n",
    "X_train, y_train, X_test, y_test=train_test(movies_scaled,user_data)\n",
    "model = train_model(X_train, y_train, X_test, y_test)\n",
    "# Get user input data\n",
    "user_data = get_user_data()\n",
    "# Recommend movie based on trained model\n",
    "recommend_movie(model, user_data, movies_scaled, movies_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'movie_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'movie_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Find the movie name\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m movie_name \u001b[38;5;241m=\u001b[39m movies\u001b[38;5;241m.\u001b[39mloc[movies[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m movie_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended Movie:\u001b[39m\u001b[38;5;124m\"\u001b[39m, movie_name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'movie_id'"
     ]
    }
   ],
   "source": [
    "# Find the movie name\n",
    "movie_name = movies.loc[movies['movie_id'] == movie_id, 'movie_name']\n",
    "print(\"Recommended Movie:\", movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
