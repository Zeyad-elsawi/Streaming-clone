{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOprLWq/OvCRVTy3h+4QJNi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zeyad-elsawi/Streaming-clone/blob/main/Not_a_Flex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eeWCiqOWf7xx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(movies_file, ratings_file):\n",
        "    # Load the data from CSV files\n",
        "    movies = pd.read_csv(movies_file)\n",
        "    ratings = pd.read_csv(ratings_file)\n",
        "\n",
        "    # Print the columns to debug\n",
        "    print(\"Movies DataFrame columns:\", movies.columns)\n",
        "\n",
        "    # Check if 'title' exists in movies DataFrame\n",
        "    if 'title' not in movies.columns:\n",
        "        raise KeyError(\"The 'title' column is missing in the movies DataFrame.\")\n",
        "\n",
        "    # Create a list of genres for binary encoding\n",
        "    genres = [\n",
        "        'Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
        "        'Crime', 'Documentary', 'Drama', 'Fantasy', 'Horror',\n",
        "        'Mystery', 'Romance', 'Sci-Fi', 'Thriller'\n",
        "    ]\n",
        "\n",
        "    # Prepare the movies DataFrame\n",
        "    # Extract year from title and compute average ratings\n",
        "    movies['year'] = movies['title'].str.extract(r'\\((\\d{4})\\)')\n",
        "    movies['title'] = movies['title'].str.replace(r'\\s*\\(\\d{4}\\)', '', regex=True).str.strip()\n",
        "\n",
        "    # Calculate average ratings for each movie\n",
        "    avg_ratings = ratings.groupby('movieId')['rating'].mean().reset_index()\n",
        "    avg_ratings.columns = ['movieId', 'avg_rating']\n",
        "\n",
        "    # Merge the average ratings with movies DataFrame\n",
        "    movies = movies.merge(avg_ratings, on='movieId', how='left')\n",
        "\n",
        "    # One-hot encode genres into binary columns\n",
        "    for genre in genres:\n",
        "        movies[genre] = movies['genres'].str.contains(genre).astype(int)\n",
        "\n",
        "    # Drop the original genres column\n",
        "    movies = movies.drop(columns=['genres', 'title'], axis=1)\n",
        "\n",
        "    # Prepare the user DataFrame\n",
        "    user_data = ratings.groupby('userId').agg(\n",
        "        rating_count=('rating', 'count'),\n",
        "        avg_rating=('rating', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    # Calculate average ratings for each genre per user\n",
        "    for genre in genres:\n",
        "        user_data[genre + '_avg'] = \\\n",
        "        ratings[ratings['movieId'].isin(movies[movies[genre] == 1]['movieId'])].groupby('userId')[\n",
        "            'rating'].mean().fillna(0)\n",
        "\n",
        "    # Merge user data with the binary genre data\n",
        "    user_data = user_data.fillna(0)\n",
        "    # Return user data, movies, and the original movies DataFrame\n",
        "    return user_data, movies, movies\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_user_data():\n",
        "    ratings_df = pd.read_csv('ratings.csv')  # Adjust the filename as needed\n",
        "    lastid = ratings_df['userId'].iloc[-1]\n",
        "    user_data = []\n",
        "\n",
        "    # Collecting user input for the ratings\n",
        "    user_data.append(int(lastid + 1))\n",
        "    user_data.append(float(input(\"Enter the Average rating: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Action: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Adventure: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Animation: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Children: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Comedy: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Crime: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Documentary: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Drama: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Fantasy: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Horror: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Mystery: \")))\n",
        "    user_data.append(float(input(\"Enter the rating of Romance: \")))\n",
        "\n",
        "    return user_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oDy4jTDXf--B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train, X_test, y_test):\n",
        "    # Neural networks for user and movie vectors\n",
        "    user_NN = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(32),\n",
        "    ])\n",
        "\n",
        "    movie_NN = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(32),\n",
        "    ])\n",
        "\n",
        "    # Inputs for users and movies\n",
        "    user_input = tf.keras.Input(shape=(X_train.shape[1],))\n",
        "    movie_input = tf.keras.Input(shape=(y_train.shape[1],))\n",
        "\n",
        "    # Get user and movie vectors\n",
        "    user_vector = user_NN(user_input)\n",
        "    movie_vector = movie_NN(movie_input)\n",
        "\n",
        "\n",
        "    # Compute dot product\n",
        "    output = tf.keras.layers.Dot(axes=1)([user_vector, movie_vector])\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = tf.keras.Model(inputs=[user_input, movie_input], outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                  loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "    # Train the model\n",
        "    model.fit([X_train, y_train], y_train, epochs=10, batch_size=32)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss = model.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {loss}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "Tp10TJr1hJ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movie(model, user_data, movies_scaled, movies_original):\n",
        "    user_vector = np.expand_dims(user_data, axis=0)\n",
        "    predicted_ratings = model.predict([user_vector, movies_scaled])\n",
        "\n",
        "    # Get the index of the highest predicted rating\n",
        "    top_movie_index = np.argmax(predicted_ratings)\n",
        "\n",
        "    # Retrieve the recommended movie from the original dataset\n",
        "    recommended_movie = movies_original.iloc[top_movie_index]\n",
        "    print(f\"We recommend you to watch: {recommended_movie['title']}\")"
      ],
      "metadata": {
        "id": "y7fVn5u7hXXK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}